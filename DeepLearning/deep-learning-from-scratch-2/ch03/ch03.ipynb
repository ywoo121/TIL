{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# ch03. word2vec\n",
    "'추론 기반 학습' : 추론 (word2vec)\n",
    "\n",
    "## 3.1 추론 기반 기법과 신경망\n",
    "단어를 벡터로 표현하는 방법\n",
    "- 통계 기반 기법\n",
    "- 추론 기반 기법\n",
    "\n",
    "### 3.1.1 통계 기반 기법의 문제점\n",
    "통계 기반 기법 : 주변 단어의 빈도를 기초로 단어 표현\n",
    "- 단어의 동시 발생 행렬\n",
    "- 그 행렬에 SVD 적용\n",
    "- 밀집벡터 표현을 얻음\n",
    "- 하지만 이 방식은 대규모 말뭉치를 담을 때 문제 발생함\n",
    "\n",
    "=> 말뭉치 전체의 통계를 이용해 **단 1회의 처리**만에 단어의 분산 표현을 얻음\n",
    "\n",
    "추론 기반 기법: 신경망을 이용하는 경우는 **미니배치**로 학습하는 것이 일반적\n",
    "- 미니배치 학습: 신경망이 한 번에 소량의 학습 샘플씩 반복해서 학습하며 가중치를 갱신해 감\n",
    "\n",
    "![통계 기반 기법과 추론 기반 기법 비교](img/3-1.png)\n",
    "\n",
    "[통계 기반 기법]\n",
    "- 학습 데이터를 한꺼번에 처리 (배치 학습)\n",
    "\n",
    "[추론 기반 기법]\n",
    "- 학습 데이터의 일부를 사용하여 순차적으로 학습 (미니배치 학습)\n",
    "- 여러 머신과 여러 GPU를 이용한 병렬 계산도 가능\n",
    "- 학습 속도를 높일 수 있음"
   ],
   "id": "21b85637c3ab1ef6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 3.1.2 추론 기반 기법 개요\n",
    "추론: 주변 단어(맥락)이 주어졌을 때 \"?\" 안에 무슨 단어가 들어가는지를 추측하는 작업\n",
    "![](img/3-2.png)\n",
    "\n",
    "=> 이러한 추론 문제를 반복해 풀면서 단어의 출현 패턴을 학습하는 것\n",
    "![](img/3-3.png)\n",
    "\n",
    "* 모델: 맥락 정보를 입력받아 (출현할 수 있는) 각 단어의 출현 확률 출력\n",
    "* 이러한 틀 안에서 말뭉치를 사용해 모델이 올바른 추측을 할 수 있도록\n",
    "* 그 학습의 결과로 단어의 분산 표현을 얻는 것이 추론 기반 기법의 전체 그림"
   ],
   "id": "e2a18c14a1bface9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 3.1.3 신경망에서의 단어 처리\n",
    "신경망: \"you\", \"say\"와 은 단어를 있는 그대로 처리X -> 단어를 _고정 길이의 벡터_ 로 변환해야.\n",
    "- 이 때 사용하는 방법: 원핫 표현 (원핫 벡터)\n",
    "\n",
    "-> 벡터의 원소 중 하나만 1이고 나머지는 모두 0인 벡터\n",
    "\n",
    "1. 총 어휘 수만큼의 원소를 갖는 벡터 준비\n",
    "2. 인덱스가 단어 ID와 같은 원소를 1로, 나머지는 모두 0으로 설정\n",
    "-> 단어를 고정 길이 벡터로 변환하면 우리 신경망의 입력층은 뉴런의 수를 **고정** 할 수 있음\n",
    "\n",
    "![](img/3-5.png)\n",
    "\n",
    "=> 단어를 벡터로 나타낼 수 있고, 신경망을 구성하는 계층들은 벡터를 처리할 수 있음\n",
    "\n",
    "![](img/3-7.png)"
   ],
   "id": "f8977628ed16a228"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T14:33:28.686757Z",
     "start_time": "2024-12-08T14:33:28.466277Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "c = np.array([[1, 0, 0, 0, 0, 0, 0]])   # 입력\n",
    "W = np.random.randn(7, 3)               # 가중치\n",
    "h = np.matmul(c, W)                     # 중간 노\n",
    "print(h)"
   ],
   "id": "3d9979e5ebb52034",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.15399587 -0.39786194  0.26368861]]\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "단어 ID가 0인 단어를 원핫 표현으로 표현한 다음 완전연결계층 (matmul)",
   "id": "56160620ff599cfa"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 3.2 단순한 word2vec\n",
    "=> CBOW(continous bag-of-words) 모델 사용\n",
    "\n",
    "### 3.2.1 CBOW 모델의 추론 처리\n"
   ],
   "id": "2fe23138edb3aecd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T06:07:58.874056Z",
     "start_time": "2024-12-10T06:07:58.839075Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import numpy as np\n",
    "from common.layers import MatMul\n",
    "\n",
    "c0 = np.array([[1, 0, 0, 0, 0, 0, 0]])\n",
    "c1 = np.array([[0, 0, 1, 0, 0, 0, 0]])\n",
    "\n",
    "# 가중치 초기\n",
    "W_in = np.random.randn(7, 3)\n",
    "W_out = np.random.randn(3, 7)\n",
    "\n",
    "# 계층 생성\n",
    "in_layer0 = MatMul(W_in)\n",
    "in_layer1 = MatMul(W_in)\n",
    "out_layer = MatMul(W_out)\n",
    "\n",
    "# 순전파\n",
    "h0 = in_layer0.forward(c0)\n",
    "h1 = in_layer1.forward(c1)\n",
    "h = 0.5 * (h0 + h1)\n",
    "s = out_layer.forward(h)\n",
    "\n",
    "print(s)"
   ],
   "id": "5454ce6bcabc7dad",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.68351986 -0.51137835 -1.23924066 -1.20130729 -1.13300778 -0.956684\n",
      "  -2.8252252 ]]\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 3.2.2 CBOW 모델의 학습\n",
    "CBOW 모델: 출력층에서 각 단어의 점수 출력\n",
    "\n",
    "-> softmax 적용: '확률'을 얻을 수 있음 (맥락이 주어졌을 때 그 중앙에 어떤 단어가 출현하는지)\n",
    "\n",
    "\n",
    "- 소프트맥스 함수를 이용해 점수를 확률으로 변환\n",
    "- 확률을 정답 레이블로부터 교차 엔트로피 오차를 구한 후\n",
    "- 그 값을 손실로 사용해 학습 진행\n",
    "![](img/3-14.png)\n"
   ],
   "id": "1418579fe9040ce8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 3.2.3 word2vec의 가중치와 분산 표현\n",
    "<word2vec에서 사용하는 가중치>\n",
    "- 입력 측 완전연결계층의 가중치 (w_in)\n",
    "- 출력 측 완전연결계층의 가중치 (w_out)\n",
    "\n",
    "<각 단어의 분산 표현>\n",
    "- 입력 측 가중치 W_in의 행\n",
    "- 출력 측 가중치 W_out의 열\n",
    "\n",
    "<최종적으로 이용하는 단어의 분산 표현으로는...?>\n",
    "**1. 입력 측의 가중치만 이용한다**\n",
    "2. 출력 측의 가중치만 이용한다\n",
    "3. 양쪽 가중치를 모두 이용한다\n",
    "\n",
    "> 많은 연구에서 출력 측 가중치는 버리고 입력 측 가중치 (W_in)만을\n",
    "> 최종 단어의 분산 표현으로 이용함"
   ],
   "id": "579e28d5cb653b44"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 3.3 학습 데이터 준비\n",
    "### 3.3.1 맥락과 타깃\n"
   ],
   "id": "ce1752ad62bc361d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T08:32:32.335975Z",
     "start_time": "2024-12-10T08:32:32.332690Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "sys.path.append(\"..\")\n",
    "from common.util import preprocess\n",
    "\n",
    "text = \"You say goodbye and I say hello.\"\n",
    "corpus, word_to_id, id_to_word = preprocess(text)\n",
    "print(corpus)\n",
    "\n",
    "print(id_to_word)"
   ],
   "id": "e1adba902eae4533",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 1 5 6]\n",
      "{0: 'you', 1: 'say', 2: 'goodbye', 3: 'and', 4: 'i', 5: 'hello', 6: '.'}\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T08:32:51.915575Z",
     "start_time": "2024-12-10T08:32:51.910636Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 맥락과 타깃을 만드는 함수\n",
    "def create_contexts_target(corpus, window_size=1):\n",
    "    target = corpus[window_size:-window_size]\n",
    "    contexts = []\n",
    "\n",
    "    for idx in range(window_size, len(corpus)-window_size):\n",
    "        cs = []\n",
    "        for t in range(-window_size, window_size+1):\n",
    "            if t == 0: continue\n",
    "            cs.append(corpus[idx+t])\n",
    "        contexts.append(cs)\n",
    "\n",
    "    return np.array(contexts), np.array(target)"
   ],
   "id": "cfb5dbc8a5df8d6c",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T08:32:52.535434Z",
     "start_time": "2024-12-10T08:32:52.531888Z"
    }
   },
   "cell_type": "code",
   "source": [
    "contexts, target = create_contexts_target(corpus, window_size=1)\n",
    "print(contexts)\n",
    "print(target)"
   ],
   "id": "dcd3463ca372fbb8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 2]\n",
      " [1 3]\n",
      " [2 4]\n",
      " [3 1]\n",
      " [4 5]\n",
      " [1 6]]\n",
      "[1 2 3 4 1 5]\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 3.3.2 원핫 표현으로 변환\n",
    "맥락 & 타깃 -> 단어 ID에서 원핫 표현으로 변환\n",
    "\n",
    "**다차원 배열의 형상** 에 주목해야 함"
   ],
   "id": "3829c17c3df8e7b5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T08:36:00.981371Z",
     "start_time": "2024-12-10T08:36:00.977480Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from common.util import preprocess, create_contexts_target, convert_one_hot\n",
    "\n",
    "text = \"You say goodbye and I say hello.\"\n",
    "corpus, word_to_id, id_to_word = preprocess(text)\n",
    "\n",
    "contexts, target = create_contexts_target(corpus, window_size=1)\n",
    "\n",
    "vocab_size = len(word_to_id)\n",
    "target = convert_one_hot(target, vocab_size)\n",
    "contexts = convert_one_hot(contexts, vocab_size)"
   ],
   "id": "8a16a07799d47405",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 3.4 CBOW 모델 구현\n",
    "이번 장에는 간단한 cbow 모델 구현"
   ],
   "id": "661278cbced242b4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T08:52:33.841406Z",
     "start_time": "2024-12-10T08:52:33.826397Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import numpy as np\n",
    "from common.layers import MatMul, SoftmaxWithLoss\n",
    "\n",
    "class SimpleCBOW:\n",
    "    def __init__(self, vocab_size, hidden_size):\n",
    "        V, H = vocab_size, hidden_size\n",
    "\n",
    "        # 가중치 초기화\n",
    "        W_in = 0.01 * np.random.rand(V, H).astype('float32')\n",
    "        W_out = 0.01 * np.random.rand(V, H).astype('float32')\n",
    "\n",
    "        # 계층 생성\n",
    "        self.in_layer0 = MatMul(W_in)\n",
    "        self.in_layer1 = MatMul(W_in)\n",
    "        self.out_layer = MatMul(W_out)\n",
    "        self.loss_layer = SoftmaxWithLoss()\n",
    "\n",
    "        # 모든 가중치와 기울기를 리스트에 모음\n",
    "        layers = [self.in_layer0, self.in_layer1, self.out_layer]\n",
    "        self.params, self.grads = [], []\n",
    "        for layer in layers:\n",
    "            self.params += layer.params\n",
    "            self.grads += layer.grads\n",
    "\n",
    "        self.word_vecs = W_in\n",
    "\n",
    "\n",
    "    def forward(self, context, target):\n",
    "        h0 = self.in_layer0.forward(context[:, 0])\n",
    "        h1 = self.in_layer0.forward(context[:, 1])\n",
    "        h = 0.5 * (h0 + h1)\n",
    "        score = self.out_layer.forward(h)\n",
    "        loss = self.loss_layer.forward(score, target)\n",
    "        return loss\n",
    "\n",
    "    def backward(self, dout=1):\n",
    "        ds = self.loss_layer.backward(dout)\n",
    "        da = self.out_layer(ds)\n",
    "        da *= 0.5\n",
    "        self.in_layer1.backward(da)\n",
    "        self.in_layer0.backward(da)\n",
    "        return None"
   ],
   "id": "9e20ac23495119e5",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "7a1e1dfe48c28766"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T09:02:35.268998Z",
     "start_time": "2024-12-10T09:02:34.913511Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from common.trainer import Trainer\n",
    "from common.optimizer import Adam\n",
    "from common.util import preprocess, create_contexts_target, convert_one_hot\n",
    "\n",
    "window_size = 1\n",
    "hidden_size = 5\n",
    "batch_size = 3\n",
    "max_epochs = 1000\n",
    "\n",
    "text = \"You say goodbye and I say hello.\"\n",
    "corpus, id_to_word, word_to_id = preprocess(text)\n",
    "\n",
    "vocab_size = len(word_to_id)\n",
    "contexts, target = create_contexts_target(corpus, window_size=1)\n",
    "target = convert_one_hot(target, vocab_size)\n",
    "contexts = convert_one_hot(contexts, vocab_size)\n",
    "\n",
    "model = SimpleCBOW(vocab_size, hidden_size)\n",
    "optimizer = Adam(model.params, lr=0.001)\n",
    "trainer = Trainer(model, optimizer)\n",
    "\n",
    "trainer.fit(contexts, target, max_epochs, batch_size)\n",
    "trainer.plot()"
   ],
   "id": "8c5afd266044b0bf",
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "dlopen(/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/PIL/_imaging.cpython-310-darwin.so, 0x0002): symbol not found in flat namespace '_jpeg_resync_to_restart'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[15], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01msys\u001B[39;00m\n\u001B[1;32m      2\u001B[0m sys\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mappend(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m..\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m----> 3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mcommon\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtrainer\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Trainer\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mcommon\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01moptimizer\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Adam\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mcommon\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutil\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m preprocess, create_contexts_target, convert_one_hot\n",
      "File \u001B[0;32m~/Desktop/GitHub/STUDY/DeepLearning/deep-learning-from-scratch-2/ch03/../common/trainer.py:6\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtime\u001B[39;00m\n\u001B[0;32m----> 6\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpyplot\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mplt\u001B[39;00m\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mcommon\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mnp\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;241m*\u001B[39m  \u001B[38;5;66;03m# import numpy as np\u001B[39;00m\n\u001B[1;32m      8\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mcommon\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutil\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m clip_grads\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/matplotlib/__init__.py:159\u001B[0m\n\u001B[1;32m    155\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpackaging\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mversion\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m parse \u001B[38;5;28;01mas\u001B[39;00m parse_version\n\u001B[1;32m    157\u001B[0m \u001B[38;5;66;03m# cbook must import matplotlib only within function\u001B[39;00m\n\u001B[1;32m    158\u001B[0m \u001B[38;5;66;03m# definitions, so it is safe to import from it here.\u001B[39;00m\n\u001B[0;32m--> 159\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m _api, _version, cbook, _docstring, rcsetup\n\u001B[1;32m    160\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcbook\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m sanitize_sequence\n\u001B[1;32m    161\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_api\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m MatplotlibDeprecationWarning\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/matplotlib/rcsetup.py:28\u001B[0m\n\u001B[1;32m     26\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbackends\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m BackendFilter, backend_registry\n\u001B[1;32m     27\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcbook\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ls_mapper\n\u001B[0;32m---> 28\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcolors\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Colormap, is_color_like\n\u001B[1;32m     29\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_fontconfig_pattern\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m parse_fontconfig_pattern\n\u001B[1;32m     30\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_enums\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m JoinStyle, CapStyle\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/matplotlib/colors.py:52\u001B[0m\n\u001B[1;32m     49\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mnumbers\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Real\n\u001B[1;32m     50\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mre\u001B[39;00m\n\u001B[0;32m---> 52\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mPIL\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Image\n\u001B[1;32m     53\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mPIL\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mPngImagePlugin\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m PngInfo\n\u001B[1;32m     55\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mmpl\u001B[39;00m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/PIL/Image.py:97\u001B[0m\n\u001B[1;32m     88\u001B[0m MAX_IMAGE_PIXELS: \u001B[38;5;28mint\u001B[39m \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mint\u001B[39m(\u001B[38;5;241m1024\u001B[39m \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m1024\u001B[39m \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m1024\u001B[39m \u001B[38;5;241m/\u001B[39m\u001B[38;5;241m/\u001B[39m \u001B[38;5;241m4\u001B[39m \u001B[38;5;241m/\u001B[39m\u001B[38;5;241m/\u001B[39m \u001B[38;5;241m3\u001B[39m)\n\u001B[1;32m     91\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     92\u001B[0m     \u001B[38;5;66;03m# If the _imaging C module is not present, Pillow will not load.\u001B[39;00m\n\u001B[1;32m     93\u001B[0m     \u001B[38;5;66;03m# Note that other modules should not refer to _imaging directly;\u001B[39;00m\n\u001B[1;32m     94\u001B[0m     \u001B[38;5;66;03m# import Image and use the Image.core variable instead.\u001B[39;00m\n\u001B[1;32m     95\u001B[0m     \u001B[38;5;66;03m# Also note that Image.core is not a publicly documented interface,\u001B[39;00m\n\u001B[1;32m     96\u001B[0m     \u001B[38;5;66;03m# and should be considered private and subject to change.\u001B[39;00m\n\u001B[0;32m---> 97\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m _imaging \u001B[38;5;28;01mas\u001B[39;00m core\n\u001B[1;32m     99\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m __version__ \u001B[38;5;241m!=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(core, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPILLOW_VERSION\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m    100\u001B[0m         msg \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m    101\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe _imaging extension was built for another version of Pillow or PIL:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    102\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCore version: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mgetattr\u001B[39m(core,\u001B[38;5;250m \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mPILLOW_VERSION\u001B[39m\u001B[38;5;124m'\u001B[39m,\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    103\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPillow version: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m__version__\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    104\u001B[0m         )\n",
      "\u001B[0;31mImportError\u001B[0m: dlopen(/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/PIL/_imaging.cpython-310-darwin.so, 0x0002): symbol not found in flat namespace '_jpeg_resync_to_restart'"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 3.5 word2vec 보충\n",
    "- CBOW 모델: 맥락이 여러 개, 그 맥락들로부터 중앙의 단어 (타깃) 추측\n",
    "- skip-gram 모델: 중앙의 단어로부터 주변의 여러 단어(맥락)을 추측\n",
    "\n",
    "=> 말뭉치가 커질 수록 저빈도 단어나 유추 문제의 성능 면에서 skip-gram모델이 더 뛰어남"
   ],
   "id": "96d42e65c7b91a8a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 3.5.3. 통계 기반 vs. 추론 기반\n",
    "- 통계 기반: 말뭉치의 전체 통계로부터 1회 학습하여 단어의 분산 표현을 얻음\n",
    "    - 새 단어가 생기면? 계산을 처음부터 다시. (동시발생행렬 -> SVD)\n",
    "    - 단어의 유사성이 인코딩됨\n",
    "- 추론 기반: 말뭉치를 일부분씩 여러 번 보면서 학습 (미니배치)\n",
    "    - 매개변수 다시 학습 가능\n",
    "    - 기존에 학습한 경험을 해치지 않으면서 단어의 분산 표현을 효율적으로 갱신할 수 있음\n",
    "    - 복잡한 단어 사이의 패턴까지도 파악되어 인코딩됨.\n",
    "\n",
    "\n",
    "## 3.6 정리\n",
    "- CBOW : 기본적으로2 층 구성의 아주 단순한 신경망\n",
    "\n",
    "---\n",
    "\n",
    "### 이번 장에서 배운 내용\n",
    "- 추론 기반 기법은 추측하는 것이 목적이며, 그 부산물로 단어의 분산 표현을 얻을 수 있다.\n",
    "- word2vec은 추론 기반 기법이며, 단순한 2층 신경망이다\n",
    "- word2vec은 skip-gram 모델과 CBOW 모델을 제공한다.\n",
    "- CBOW 모델은 여러 단어로부터 하나의 단어를 추측한다\n",
    "- skip-gram 모델은 하나의 단어로부터 다수의 단어를 추측한다.\n",
    "- word2vec은 가중치를 다시 학습할 수 있으므로, 단어의 분산 표현이나 새로운 단어 추각를 효율적으로 수행할 수 있다.   "
   ],
   "id": "9c459ea379de6034"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
